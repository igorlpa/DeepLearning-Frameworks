{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "894e37d6-65c9-4f5b-93dc-954fe4b858ed",
   "metadata": {},
   "source": [
    "# CNN para classificação - CIFAR10\n",
    "\n",
    "Como criar e treinar uma rede usando CNN em Pythorch.\n",
    "Nesse script iremos usaro dataset CIFAR10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cdad3e8-ae84-4f38-813b-313485483827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# PyTorch dataset\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "# PyTorch model\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d87cae94-d77f-43ae-98b9-2e4e46dc8917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0bb1f8-bd23-4588-8e94-6af1a51d74f0",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "866dea8e-e27e-44e6-b1c0-74ff88a1fdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "valid_size = 0.2 # proporção da divisão do banco de treinamento em train e valid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c784cbf9-c0ae-4287-b3dc-33a24521654a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.RandomAutocontrast(0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ae84046-6678-42c9-90d1-5e91d15e2e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Baixar os datasets\n",
    "train_data = datasets.CIFAR10('data', train=True,\n",
    "                              download=True, transform=train_transform)\n",
    "test_data = datasets.CIFAR10('data', train=False,\n",
    "                             download=True, transform=test_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155d816c-d001-4605-a255-fdedbb70c75e",
   "metadata": {},
   "source": [
    "- Dividir o dataset de treinamento  em em treinamento e validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69673ca7-6d74-4354-b170-60bc5d47f9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = len(train_data)\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(valid_size * num_train))\n",
    "train_idx, valid_idx = indices[split:], indices[:split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06da2d4d-b600-48c9-ad3f-60c0b1e427b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57acb632-cac4-492e-8a92-8c31ff15d5d9",
   "metadata": {},
   "source": [
    "Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27b5f5a5-502e-437b-ad16-5e6fea305d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,sampler=train_sampler)\n",
    "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=valid_sampler)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a72521e2-4190-4008-a59b-7ff6ef3a7fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['airplane',\n",
       " 'automobile',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'deer',\n",
       " 'dog',\n",
       " 'frog',\n",
       " 'horse',\n",
       " 'ship',\n",
       " 'truck']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fb823b-d83d-4f06-b2a4-85ab20330ff8",
   "metadata": {},
   "source": [
    "## Definindo a arquitetura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b7162a5-0aca-48b0-93ca-16f2063629d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        \n",
    "        self.max = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.linear = nn.Linear( 8*8*32, 256)\n",
    "        self.output = nn.Linear( 256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 32,32,3\n",
    "        x = self.relu(self.conv1(x))  # 32,32,16\n",
    "        x = self.max(x) # 16,16,3\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.relu(self.conv2(x)) # 16,16,32\n",
    "        x = self.max(x) # 8, 8, 32\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        x = self.dropout(self.linear(x))\n",
    "        x = self.output(x)     \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74137bbb-d7f8-4351-aad2-8f6b4bb9bc32",
   "metadata": {},
   "source": [
    "- Criar a rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38ab2588-bb31-49a5-9e8d-9371e943c06f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (max): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (relu): ReLU()\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear): Linear(in_features=2048, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4347963-bd74-4ac8-84c6-d53a57116ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (max): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (relu): ReLU()\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear): Linear(in_features=2048, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba97859-04e4-4d1f-b5f9-efb802f13dd2",
   "metadata": {},
   "source": [
    "- função de perda e otimizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbef10d6-29bc-4cef-a86f-17a955e4fc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f375655-f508-464b-bde6-42ab2b9bd991",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b85e95b-d445-4773-bee6-1e3b063416b0",
   "metadata": {},
   "source": [
    "## Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54c8cc20-c539-41d2-9cad-b09d41b7f7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 30\n",
    "\n",
    "valid_loss_min = np.Inf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c95354a3-fcf2-4e30-bddd-750bb19c3a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 2.023996 \tValidation Loss: 1.843944\n",
      "Validation loss decreased (inf --> 1.843944).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 1.726765 \tValidation Loss: 1.595590\n",
      "Validation loss decreased (1.843944 --> 1.595590).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 1.570242 \tValidation Loss: 1.526904\n",
      "Validation loss decreased (1.595590 --> 1.526904).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 1.493770 \tValidation Loss: 1.449503\n",
      "Validation loss decreased (1.526904 --> 1.449503).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 1.445041 \tValidation Loss: 1.390101\n",
      "Validation loss decreased (1.449503 --> 1.390101).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 1.406915 \tValidation Loss: 1.385088\n",
      "Validation loss decreased (1.390101 --> 1.385088).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 1.370771 \tValidation Loss: 1.312195\n",
      "Validation loss decreased (1.385088 --> 1.312195).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.340893 \tValidation Loss: 1.305970\n",
      "Validation loss decreased (1.312195 --> 1.305970).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.311300 \tValidation Loss: 1.266128\n",
      "Validation loss decreased (1.305970 --> 1.266128).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.292522 \tValidation Loss: 1.244738\n",
      "Validation loss decreased (1.266128 --> 1.244738).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.275271 \tValidation Loss: 1.232800\n",
      "Validation loss decreased (1.244738 --> 1.232800).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.254085 \tValidation Loss: 1.198097\n",
      "Validation loss decreased (1.232800 --> 1.198097).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.241572 \tValidation Loss: 1.201170\n",
      "Epoch: 14 \tTraining Loss: 1.222981 \tValidation Loss: 1.175935\n",
      "Validation loss decreased (1.198097 --> 1.175935).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.211534 \tValidation Loss: 1.153288\n",
      "Validation loss decreased (1.175935 --> 1.153288).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 1.198964 \tValidation Loss: 1.133085\n",
      "Validation loss decreased (1.153288 --> 1.133085).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 1.193788 \tValidation Loss: 1.138121\n",
      "Epoch: 18 \tTraining Loss: 1.180978 \tValidation Loss: 1.140687\n",
      "Epoch: 19 \tTraining Loss: 1.173035 \tValidation Loss: 1.135815\n",
      "Epoch: 20 \tTraining Loss: 1.163540 \tValidation Loss: 1.118918\n",
      "Validation loss decreased (1.133085 --> 1.118918).  Saving model ...\n",
      "Epoch: 21 \tTraining Loss: 1.152825 \tValidation Loss: 1.107895\n",
      "Validation loss decreased (1.118918 --> 1.107895).  Saving model ...\n",
      "Epoch: 22 \tTraining Loss: 1.149149 \tValidation Loss: 1.100365\n",
      "Validation loss decreased (1.107895 --> 1.100365).  Saving model ...\n",
      "Epoch: 23 \tTraining Loss: 1.148565 \tValidation Loss: 1.115650\n",
      "Epoch: 24 \tTraining Loss: 1.141831 \tValidation Loss: 1.114406\n",
      "Epoch: 25 \tTraining Loss: 1.137131 \tValidation Loss: 1.100541\n",
      "Epoch: 26 \tTraining Loss: 1.128739 \tValidation Loss: 1.073327\n",
      "Validation loss decreased (1.100365 --> 1.073327).  Saving model ...\n",
      "Epoch: 27 \tTraining Loss: 1.123472 \tValidation Loss: 1.075064\n",
      "Epoch: 28 \tTraining Loss: 1.123623 \tValidation Loss: 1.077799\n",
      "Epoch: 29 \tTraining Loss: 1.115988 \tValidation Loss: 1.076433\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs):\n",
    "\n",
    "    # keep track of training and validation loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    model.train()\n",
    "    for data, target in train_loader:\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #print('debug devices: ', \n",
    "        output = model(data)\n",
    "\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        \n",
    "    ######################    \n",
    "    # validate the model #\n",
    "    ######################\n",
    "    model.eval() # não usar os dados para treinamento e otimiza o calculo\n",
    "    for data, target in valid_loader:\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "    \n",
    "    # calculate average losses\n",
    "    train_loss = train_loss/len(train_loader.sampler)\n",
    "    valid_loss = valid_loss/len(valid_loader.sampler)\n",
    "        \n",
    "    # print training/validation statistics \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch, train_loss, valid_loss))\n",
    "    \n",
    "    # save model if validation loss has decreased\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min,\n",
    "        valid_loss))\n",
    "        torch.save(model.state_dict(), 'model_cifar.pt')\n",
    "        valid_loss_min = valid_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bf9fda-bd30-44d1-99de-dc595aa7df02",
   "metadata": {},
   "source": [
    "## Teste do resultado\n",
    "\n",
    "- carregar o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42e86a9a-e697-4b8a-af9f-196e0670b317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model_cifar.pt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17c04ad7-1929-4c18-8143-005db3cb5616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.980434\n",
      "\n",
      "Test Accuracy of airplane: 68% (684/1000)\n",
      "Test Accuracy of automobile: 77% (779/1000)\n",
      "Test Accuracy of  bird: 47% (479/1000)\n",
      "Test Accuracy of   cat: 46% (469/1000)\n",
      "Test Accuracy of  deer: 64% (648/1000)\n",
      "Test Accuracy of   dog: 55% (556/1000)\n",
      "Test Accuracy of  frog: 75% (751/1000)\n",
      "Test Accuracy of horse: 70% (705/1000)\n",
      "Test Accuracy of  ship: 82% (820/1000)\n",
      "Test Accuracy of truck: 69% (692/1000)\n",
      "\n",
      "Test Accuracy (Overall): 65% (6583/10000)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_loss = 0.0\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "model.eval()  # não mudar pesos e ser otimizado\n",
    "\n",
    "\n",
    "for data, target in test_loader:\n",
    "    \n",
    "    data = data.to(device)\n",
    "    target = target.to(device)\n",
    "    \n",
    "    output = model(data)\n",
    "    loss = criterion(output, target)\n",
    "    test_loss += loss.item()*data.size(0)\n",
    "    \n",
    "    # convert output probabilities to predicted class\n",
    "    _, pred = torch.max(output, 1)    \n",
    "    # compare predictions to true label\n",
    "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "    \n",
    "    correct = np.squeeze(correct_tensor.numpy()) if device=='cpu' else np.squeeze(correct_tensor.cpu().numpy())\n",
    "    \n",
    "    # calculate test accuracy for each object class\n",
    "    for i in range(len(target)):\n",
    "        label = target.data[i]\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1\n",
    "\n",
    "# average test loss\n",
    "test_loss = test_loss/len(test_loader.dataset)\n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "for i in range(10):\n",
    "    if class_total[i] > 0:\n",
    "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i],\n",
    "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "    else:\n",
    "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "    100. * np.sum(class_correct) / np.sum(class_total),\n",
    "    np.sum(class_correct), np.sum(class_total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6eee2d5-1533-48f8-8c63-11547c01a0f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
